{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a3cde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a9ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc3ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY is missing in your .env\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c383b740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-flash-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/deep-research-pro-preview-12-2025\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "models/gemini-2.5-flash-native-audio-preview-12-2025\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "for model in client.models.list():\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7b670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec8b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatGoogleGenerativeAI(model =\"gemini-2.5-flash\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd33a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 1048576, 'max_output_tokens': 65536, 'image_inputs': True, 'audio_inputs': True, 'pdf_inputs': True, 'video_inputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'image_tool_message': True, 'tool_choice': True} google_api_key=SecretStr('**********') model='gemini-2.5-flash' client=<google.genai.client.Client object at 0x000001A459D1A330> default_metadata=() model_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9059b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm an AI, so I don't experience feelings, but I'm ready and functioning perfectly.\\n\\nHow can I help you today?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.invoke('Hello, How are you?').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7708a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c97211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AnyMessage, HumanMessage,AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1037952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c08f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(StateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23f9315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "# help(operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd52614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['hai'] ['hai', 'how are you'] like this we can append in the list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aa52a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: GraphState) -> dict:\n",
    "    \"\"\"Call the LLM using conversation messages and append AI response.\"\"\"\n",
    "    response = chat_llm.invoke(state[\"messages\"])  # AIMessage\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb31f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_counter(state: GraphState) -> dict:\n",
    "    \"\"\"Count tokens (simple word count) in the last AI message.\"\"\"\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    text = last_msg.content\n",
    "    token_number = len(text.split())\n",
    "    summary = f\"Total token number in the generated answer (word count) is {token_number}\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=summary)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36676cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b61bf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a456d821e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"llm_call\", llm_call)\n",
    "builder.add_node(\"token_counter\", token_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d193314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a456d821e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"llm_call\")\n",
    "builder.add_edge(\"llm_call\", \"token_counter\")\n",
    "builder.set_finish_point(\"token_counter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a03f8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "016d3207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=RunnableCallable(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'llm_call': Node(id='llm_call', name='llm_call', data=llm_call(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'token_counter': Node(id='token_counter', name='token_counter', data=token_counter(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=None, metadata=None)}, edges=[Edge(source='__start__', target='llm_call', data=None, conditional=False), Edge(source='llm_call', target='token_counter', data=None, conditional=False), Edge(source='token_counter', target='__end__', data=None, conditional=False)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c354cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e6b3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72768027",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 11.344513556s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3047\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\google\\genai\\models.py:5474\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5473\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5474\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5475\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5476\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5478\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\google\\genai\\models.py:4214\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4212\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4214\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4215\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4219\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4220\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1396\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1393\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1394\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1395\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1397\u001b[39m response_body = (\n\u001b[32m   1398\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1399\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1230\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1229\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:470\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:371\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:413\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:184\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\adnan\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\adnan\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:473\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1209\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1202\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1203\u001b[39m     method=http_request.method,\n\u001b[32m   1204\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1207\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1208\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1211\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1212\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:134\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    132\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:159\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 11.344513556s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHi, this is Raj Kumar Malyala. Say hello in detail.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mllm_call\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_call\u001b[39m(state: GraphState) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the LLM using conversation messages and append AI response.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     response = \u001b[43mchat_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# AIMessage\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2535\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2532\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2533\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3051\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3048\u001b[39m         **request,\n\u001b[32m   3049\u001b[39m     )\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3051\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\adnan\\Rajkumar\\ai_agents\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 11.344513556s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}",
      "During task with name 'llm_call' and id '4e2d3ebd-508b-3869-3bf6-ee735ce75f95'"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, this is Raj Kumar Malyala. Say hello in detail.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b97598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there, Raj Kumar Malyala!\\n\\nA very warm welcome to you! It's a pleasure to connect and hear from you.\\n\\nI'm here and ready to assist you with whatever you need. How may I help you today, Raj Kumar Malyala? Please feel free to share what's on your mind or what you'd like to discuss. I'm listening!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result['messages'][1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8d9cead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi, this is Sunny. Say hello in detail.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"messages\": [HumanMessage(content=\"Hi, this is Sunny. Say hello in detail.\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a49a679d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi, this is Raj Kumar Malyala. Say hello in detail.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello there, Raj Kumar Malyala!\\n\\nA very warm welcome to you! It's a pleasure to connect and hear from you.\\n\\nI'm here and ready to assist you with whatever you need. How may I help you today, Raj Kumar Malyala? Please feel free to share what's on your mind or what you'd like to discuss. I'm listening!\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c7558-a08a-7f50-8eb4-24749f240877-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 16, 'output_tokens': 1105, 'total_tokens': 1121, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1023}}),\n",
       "  AIMessage(content='Total token number in the generated answer (word count) is 57', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19706871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage : Hi, this is Raj Kumar Malyala. Say hello in detail.\n",
      "AIMessage : Hello there, Raj Kumar Malyala!\n",
      "\n",
      "A very warm welcome to you! It's a pleasure to connect and hear from you.\n",
      "\n",
      "I'm here and ready to assist you with whatever you need. How may I help you today, Raj Kumar Malyala? Please feel free to share what's on your mind or what you'd like to discuss. I'm listening!\n",
      "AIMessage : Total token number in the generated answer (word count) is 57\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    print(type(m).__name__, \":\", m.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "820e40b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(profile={'max_input_tokens': 1048576, 'max_output_tokens': 65536, 'image_inputs': True, 'audio_inputs': True, 'pdf_inputs': True, 'video_inputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'image_tool_message': True, 'tool_choice': True}, google_api_key=SecretStr('**********'), model='gemini-2.5-flash', client=<google.genai.client.Client object at 0x00000189CCB43E60>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun # It is the inbuilt tool from the langchain_community package to query Wikipedia\n",
    "from langchain_community.utilities import WikipediaAPIWrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max= 500) # top_5 it index the top 5 results with the 500 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tool=WikipediaQueryRun(api_wrapper=api_wrapper) # fetch any sort of information from the internet using the wikidedia tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc19adf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Generative artificial intelligence\\nSummary: Generative artificial intelligence, also known as generative AI or GenAI, is a subfield of artificial intelligence that uses generative models to generate text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data, and use them to generate new data in response to input, which often takes the form of natural language prompts.\\nThe prevalence of generative AI to'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.run({'query':\"Generative AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58ada0",
   "metadata": {},
   "source": [
    "'Page: Generative artificial intelligence\\nSummary: Generative artificial intelligence, also known as generative AI or GenAI, is a subfield of artificial intelligence that uses generative models to generate text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data, and use them to generate new data in response to input, which often takes the form of natural language prompts.\\nThe prevalence of generative AI to'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43cff5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa4fa097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    print(api_key)\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving API key: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e577dfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"TAVILY_API_KEY\" in os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30d9f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SPSOFT\\AppData\\Local\\Temp\\ipykernel_18964\\1068719361.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e0e518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The 2026 Job Market: Supporting Students and Closing the Skills Gap',\n",
       "  'url': 'https://findingequilibriumfuturehighered.substack.com/p/the-2026-job-market-supporting-students',\n",
       "  'content': \"# Finding Equilibrium: Two Economists on Higher Ed's Future\\n\\n# The 2026 Job Market: Supporting Students and Closing the Skills Gap\\n\\n### Ideas for Preparing More Career-Ready Graduates\\n\\nJay Akridge and David Hummels\\n\\nDec 19, 2025\\n\\nWeve written a couple of times this fall on the current job market for new college graduates. The bottom-line: the Class of 2026 is likely to have more trouble finding a job.\\n\\nStudents are concerned: about 61% of the Class of 2026 students find current news about the job market somewhat or very pessimistic  up from 50% for the Class of 2024. High competition for jobs and lack of available jobs top the list of reasons for that pessimism, with the political climate and AI much more important factors this year relative to last.\\n\\nSource: Handshake. [...] #### Some Final Thoughts\\n\\nA soft job market for graduates is nothing new for universities, but it certainly will be new for members of the Class of 2026. So, these students deserve our very best in helping them secure that first job. That said, every university should also be revisiting the way they think about and prepare their students for a successful career. Its not only the right thing to do, in an environment where tuition revenue will become increasingly important, delivering career-ready graduates may well be the ticket to keeping the doors open\\n\\n#### Whats Next? [...] #### What About the Spring of 2026?\\n\\nLooking forward, the National Association of Colleges and Employers (NACE) conducts semi-annual surveys of employer hiring intentions. The story told in the most recent study is aligned with the above discussion of the general employment situation. The November 2025 data show that 45% of the employers surveyed describe the job market as fair  the worst characterization of the job market for new college graduates we have seen since 20-21.\\n\\nSource: NACE.\",\n",
       "  'score': 0.89545894},\n",
       " {'title': 'Hiring Flat for the College Class of 2026 - NACE',\n",
       "  'url': 'https://www.naceweb.org/job-market/trends-and-predictions/hiring-flat-for-the-college-class-of-2026',\n",
       "  'content': 'These findings are also consistent with what NACE is seeing with general employment indicators at large. NACE found that employers are less positive about the overall job market for upcoming graduates this year than they were in last several years. Currently, a plurality of employers rate the overall job market for new graduates as \"fair,\" compared to a year ago, when they characterized it as \"good.\" (See Figure 2.)\\n\\nAdditionally, the vast majority of employers (60%) say that they will maintain hiring from last year, when the job market for college graduates was flat, with fewer increasing (25%) and less decreasing (15%) hiring. [...] Join/Renew Sign In Sign Out\\n\\nYour NACE membership expires soon! >>\\n\\nX\\n\\n## Your membership ends on\\n\\nWhy Join NACE? Learn all about NACE member benefits today\\n\\nHome   /  Job Market   /  Trends & Predictions\\n\\nHiring Outlook\\n\\n# Hiring Flat for the College Class of 2026\\n\\nDate: November 11, 2025\\n\\nBy: Kevin Gray\\n\\nShare\\n\\nA A A\\n\\nhiring outlooknace insightssurveystalent acquisitiontrends and predictions\\n\\nReflecting an uncertain job market for college graduates, employers are projecting just a 1.6% increase in hiring for the Class of 2026 when compared to the Class of 2025, according to results of NACEs Job Outlook 2026 survey.\\n\\nThat flat hiring projection is consistent with the tight labor market employers reported at the end of the 2024-25 recruiting year. (See Figure 1.) [...] However, there is good news as employers are taking a long view of the job market. Among employers that are increasing hiring, the main reasons for doing so are their commitment to succession planning/importance of their talent pipelines (72.7%) and company growth (68.2%). This is a strong indication they are not giving up on professional entry-level hiring or recent college graduates, and they are focused on the future of their organizations.',\n",
       "  'score': 0.8732259},\n",
       " {'title': 'Jobs Report: Hiring Flat for 2026 Grads - Inside Higher Ed',\n",
       "  'url': 'https://www.insidehighered.com/news/students/careers/2025/11/17/jobs-report-hiring-flat-2026-grads',\n",
       "  'content': 'NACE surveyed employers between Aug. 7 and Sept. 22 of this year for their thoughts on the job market, hiring trends and salaries. About 40 percent of employers plan to increase salaries for bachelors degree holders in 2026, and 28.3 percent will do the same for masters degree holders. No employers reported plans to decrease salaries for either group next year, the report states.\\n\\nSkills-based hiring remains popular69.5 percent of employers reported they use the approach. Asked how students can best prepare for a skills-based hiring process, employers primarily said applicants should prepare for interviews that demonstrate their skills, participate in experiential learning or work during college and translate college coursework into a skills language.\\n\\nAdvertisement [...] News \\n\\n Students\\n Careers\\n\\nNovember 17, 2025\\n\\n# Jobs Report: Hiring Flat for 2026 Grads\\n\\nEmployers are increasingly using skills-based hiring processes that value college internship and co-op experience over GPAs.\\n\\nBy   Emma Whitford\\n\\nYou have /3 articles left.  \\nSign up for a free account or log in.\\n\\nLogin\\n\\nA quarter of employers said they plan to increase the number of hires, primarily citing a commitment to succession planning and the talent pipeline.\\n\\nfizkes/iStock/Getty Images Plus\\n\\nForty-five percent of employers consider the job market to be fair, and they are projecting a 1.6 percent year-over-year increase in hiring for the Class of 2026, according to a new report from the National Association of Colleges and Employers. [...] The last time a plurality of employers gave the job market a fair rating was in 2021, when hiring projections were also flat. During the four interim years, most employers rated the job market as good or very good, the report shows.\\n\\nAbout 60 percent of the 183 employers NACE polled for the 2026 Job Outlook Survey said they are planning to keep the number of people they hire stable next year. A quarter of employers said they plan to increase the number of hires, primarily citing a commitment to succession planning and the talent pipeline, as well as company growth, as key reasons. The top five industries for projected hiring growth are miscellaneous professional services; engineering services; construction; finance, insurance and real estate; and management consulting.',\n",
       "  'score': 0.85509074},\n",
       " {'title': '2026 Job Market Trends Every Student Should Know',\n",
       "  'url': 'https://mohr.uoregon.edu/blog/2025/12/08/2026-job-market-trends-every-student-should-know/',\n",
       "  'content': 'Published on December 8, 2025\\n\\nIf youre starting to think seriously about life after graduation, the NACE Job Outlook 2026 Report has good news. Employers expect to bring on more new hires in 2026, and theyre prioritizing skills and experience over perfect grades. Heres what that means for you.\\n\\n## GPA Matters Less Than You Think\\n\\nOnly 42% of employers plan to screen by GPA in 2026down from 73% in 2019. Whether they check GPA or not, heres what really matters:\\n\\nTop factors for employers who dont screen by GPA:\\n\\n Academic major (94%)\\n Industry experience (81%)\\n Internships in their industry (79%)\\n Internship with their organization (74%)\\n\\nTop factors for employers who do screen by GPA: [...] 1. Prepare for skills-based interviews (89%)  Use specific examples of your problem-solving.\\n2. Get hands-on experience during college (74%)  Internships, part-time jobs, on-campus work, project work, and volunteer experience all count.\\n3. Translate coursework into skills (61%)  Developed data analysis skills beats Took Marketing 301.\\n4. Reframe extracurriculars as experience (55%)  Club treasurer = budget management experience.\\n5. Create a skills-based resume (50%)  Focus on what you can do for the employer.\\n\\n# The Work Environment\\n\\nEntry-level roles in 2026 will be 50% hybrid, 43% fully in-person, and 6% fully remote.\\n\\nTakeaway: Remote roles are rare, so be prepared for in-person or hybrid work environments.\\n\\n# Dont Panic About AI',\n",
       "  'score': 0.83932644},\n",
       " {'title': 'Where The Jobs Are In 2026And How To Actually Land One',\n",
       "  'url': 'https://www.forbes.com/sites/bryanrobinson/2026/01/18/where-the-jobs-are-in-2026-and-how-to-actually-land-one/',\n",
       "  'content': 'Houle says some candidates are going even furthersubmitting short video introductions, sharing 30-day impact plans or following up with concrete ideas on how they would tackle a roles challenges. Those signals stand out to recruiters.\\n\\nA Final Takeaway On Where The Jobs Are In 2026\\n\\nThe 2026 job market isnt broken. Experts say its fundamentally different. Healthcare, skilled trades, logistics, AI-adjacent roles and human-centered leadership positions continue to grow. At the same time, the path to those jobs has shifted away from mass applications toward alignment, visibility and relationships. [...] The jobs of 2026 are no longer living inside traditional career ladders, Houle told me. Theyre forming at the intersection of technology, creativity and human-centered leadership. Demand is rising for roles blending AI fluency with emotional intelligence, Houle explains, citing such positions such as AI integration coaches, learning and development leaders, brand and growth strategists and people-and-performance leaders.\\n\\nAcross the 2026 hiring landscape, the market has shifted from volume recruiting to precision hiring, with companies prioritizing roles that directly drive revenue, decision quality and operational efficiency, Houle states. Thats why professional services, consulting, finance, operations, logistics and data-driven customer experience roles remain resilient. [...] Hiring is more competitive and moves faster than in previous years, Houle admits. But its also more opportunity-rich for candidates who know how to show signal, not just credentials. Employers are prioritizing adaptability, learning velocity and leadership presence over perfectly linear resumes.\\n\\nYou can still snag your dream job. The major takeaway to learn where the jobs are this year, Houle argues, is to stop asking what job you want and start asking what _room_ you belong in next. In 2026, careers arent built through blind applications. Theyre built through clarity, proximity and being seen by the people shaping what comes next.\\n\\nEditorial StandardsReprints & Permissions\\n\\nImage 12: Bryan Robinson, Ph.D.',\n",
       "  'score': 0.8296166}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({\"query\":\"how is the job market for fresh graduates in 2026?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a1f194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "search=DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15c9ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Impersonate 'chrome_118' does not exist, using 'random'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"4 days ago - It was announced on June 5, 2023, at Apple's annual Worldwide Developers Conference alongside watchOS 10, iPadOS 17, tvOS 17 and macOS Sonoma. It was made publicly available on September 18, 2023 , as a free software update for supported iOS devices (see the supported devices section). 1 week ago - T-Mobiles brief corroborates this: every variant of the iPhone 17Standard, Air, Pro, and Pro Maxwas set to launch on September 19, 2025 . The 2025 iPhone 17 lineup comprises several models: iPhone 17, iPhone 17 Air, iPhone 17 Pro, and ... October 9, 2025 - The iPhone 17e is rumoured to launch in the spring of 2026 . Read on for more detailed analysis of the new iPhone 17 colors, cameras, battery life, specs, and features, plus the iPhone 17 release date and pricing. 19 hours ago - Apples iPhone 7 Plus, released in September 2016 with a promise of powerful performance and advanced camera technology, has now reached a milestone with the rollout of the latest iOS versioniOS 17bringing a fresh wave of features and refinements nearly ten years after its initial launch. But for the most part, Apple is sticking with the same price tags its slapped on its newest iPhones over recent years, just weeks after Google also held steady on prices for its new Pixel smartphones. ... Heres what to know about the iPhone 17, which officially hits stores Sept. 19  and other gadget updates. Published September 10, 2025\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is the latest update on iphone17 release?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tavily is the package is the internet search tool which is fetch the latest information from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "281719a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bingsearch, googleserperapi tools to experiment \n",
    "# from langchain_community.tools import BingSearchRun, GoogleSerperAPIWrapper\n",
    "# bing_search = BingSearchRun()\n",
    "# google_serper = GoogleSerperAPIWrapper()\n",
    "# import os\n",
    "# bing_search = BingSearchRun(api_key=os.getenv(\"BING_SUBSCRIPTION_KEY\"))\n",
    "# serper = GoogleSerperAPIWrapper(serper_api_key=os.getenv(\"SERPER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3954a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1e93ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "144b30df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d6b5d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c6fd257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=JxgmHe2NyeY&pp=ygUKa3Jpc2ggbmFpaw%3D%3D', 'https://www.youtube.com/watch?v=mbaipnzyzJg&pp=ygUKa3Jpc2ggbmFpaw%3D%3D']\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"krish naik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb4da7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=yNSCK3lCOMw&pp=ygUSZ2lmdCBvZiB0aGUgbmF0dXJl', 'https://www.youtube.com/watch?v=GsfuaU1mqmM&pp=ygUSZ2lmdCBvZiB0aGUgbmF0dXJl']\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"gift of the nature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6fc83e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating own custom tool \n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple the two integers function.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3142e18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "524e1f18",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmultiply\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m(\u001b[32m10\u001b[39m,\u001b[32m20\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "multiply.invoke(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d1bbd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmultiply\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m({\u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m10\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m20\u001b[39m})\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "multiply.invoke({\"a\":10,\"b\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "647a1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can not invoke the custom function like this because it is not the inbuilt tool of the langchain_community package.\n",
    "from langchain.tools import tool\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple the two integers function.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d536e108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\":10,\"b\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5db0a639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tool that can operate on any number of inputs.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06dfccd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2931b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multiple the two integers function.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed75e2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'title': 'A', 'type': 'integer'},\n",
       " 'b': {'title': 'B', 'type': 'integer'}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "208feb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"it is a tool to count the lenth of the word\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78f85bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length.invoke({'word': 'Raj Kumar Malyala'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc014efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length.invoke(\"hello world\")\n",
    "# we can pass as dictionary as a key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "899dbd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length.invoke({\"word\": \"hello world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aed2344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def call_gmail_api(args):\n",
    "    \"\"\"this is a tool to call gmail api\"\"\" \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e44774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def call_sqllite_db(args):\n",
    "    \"\"\"this is a tool to call sqllite db\"\"\" \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "002b607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a508468",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_stock_price(ticker:str) -> str:  #ticker is noting but the name of the stock\n",
    "    \"\"\"this is a tool to get stock price using yfinance\"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "\n",
    "        # Get last 1 day historical data\n",
    "        data = stock.history(period=\"1d\")\n",
    "\n",
    "        if data.empty:\n",
    "            return f\"No data found for ticker '{ticker}'. Please check the symbol.\"\n",
    "\n",
    "        latest_close = data[\"Close\"].iloc[-1]\n",
    "\n",
    "        # Detect currency\n",
    "        currency = stock.info.get(\"currency\", \"\")\n",
    "        symbol_map = {\n",
    "            \"INR\": \"\",\n",
    "            \"USD\": \"$\",\n",
    "            \"EUR\": \"\",\n",
    "            \"GBP\": \"\"\n",
    "        }\n",
    "\n",
    "        symbol = symbol_map.get(currency, \"\")\n",
    "        currency_text = currency if currency else \"\"\n",
    "\n",
    "        if symbol:\n",
    "            return f\"The last closing price of {ticker.upper()} was {symbol}{latest_close:.2f}.\"\n",
    "        else:\n",
    "            return f\"The last closing price of {ticker.upper()} was {latest_close:.2f} {currency_text}.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while fetching stock data: {str(e)}\"\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53401738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last closing price of TCS.NS was 2677.90.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke(\"TCS.NS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85e2154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last closing price of AAPL was $264.35.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5851ff09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last closing price of TSLA was $411.32.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke(\"TSLA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce9254ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last closing price of HDFCBANK.NS was 915.60.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke(\"HDFCBANK.NS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa0a8a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='get_stock_price', description='this is a tool to get stock price using yfinance', args_schema=<class 'langchain_core.utils.pydantic.get_stock_price'>, func=<function get_stock_price at 0x00000189CEB33920>),\n",
       " StructuredTool(name='get_word_length', description='it is a tool to count the lenth of the word', args_schema=<class 'langchain_core.utils.pydantic.get_word_length'>, func=<function get_word_length at 0x00000189CEB331A0>),\n",
       " StructuredTool(name='multiply', description='Multiple the two integers function.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x00000189CECBEC00>)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_stock_price,get_word_length,multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1da14abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how the llm decide which tool to use and how to use the tool based on the user query.\n",
    "tools = [get_stock_price,get_word_length,multiply, wiki_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b6907641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(profile={'max_input_tokens': 1048576, 'max_output_tokens': 65536, 'image_inputs': True, 'audio_inputs': True, 'pdf_inputs': True, 'video_inputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'image_tool_message': True, 'tool_choice': True}, google_api_key=SecretStr('**********'), model='gemini-2.5-flash', client=<google.genai.client.Client object at 0x00000189CCB43E60>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm #without any tool normal llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8e7a48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=chat_llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "37e79a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGoogleGenerativeAI(profile={'max_input_tokens': 1048576, 'max_output_tokens': 65536, 'image_inputs': True, 'audio_inputs': True, 'pdf_inputs': True, 'video_inputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'image_tool_message': True, 'tool_choice': True}, google_api_key=SecretStr('**********'), model='gemini-2.5-flash', client=<google.genai.client.Client object at 0x00000189CCB43E60>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'get_stock_price', 'description': 'this is a tool to get stock price using yfinance', 'parameters': {'properties': {'ticker': {'type': 'string'}}, 'required': ['ticker'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'get_word_length', 'description': 'it is a tool to count the lenth of the word', 'parameters': {'properties': {'word': {'type': 'string'}}, 'required': ['word'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiple the two integers function.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5aba7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"what is the stock price of TCS.NS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd287f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_stock_price', 'arguments': '{\"ticker\": \"TCS.NS\"}'}, '__gemini_function_call_thought_signatures__': {'c5fa0ff1-1bc0-4ed8-b4b1-9a0334d76f84': 'Cp4CAb4+9vtUXH2U1j/gkK8zdJamiNB4xLjiMipLJEoqU+g+ADFykVvKZe1/v8Ct2SEhmLar5oFhlLY/lMGUrKZfb5of635DvsQnAyNPsrVnn1CLX/sjzHu9dJftR+qSbGC6MF6FgtlqC/7lOdPOkO7EQ3ap86vMNWFWVmW7pKhgZxEKQr0NMc9cDeEgCK4LFyO7VLNSSTdyGKshcDKk5E7E5hYL7KgjQSnQWFwDLXMXNyzt4fOAJIFbtDUA6Z4Wm0qokA4WRqd3Z9i4VDSRiJ1xrb79oOxLPuJviO7BPOiYcqaCDoSRotCyjHGsi/KRi8eYTAHnd3jbjpa88HMSIUgzMXtsf1NntlqU1+yEFiDE9jhE+UE89t/ocQ/ZeBhKMw=='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c75a3-0588-70d3-a9af-e74a6665bc63-0', tool_calls=[{'name': 'get_stock_price', 'args': {'ticker': 'TCS.NS'}, 'id': 'c5fa0ff1-1bc0-4ed8-b4b1-9a0334d76f84', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 149, 'output_tokens': 95, 'total_tokens': 244, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 75}})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce5ce9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "029442a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_stock_price',\n",
       "  'args': {'ticker': 'TCS.NS'},\n",
       "  'id': 'c5fa0ff1-1bc0-4ed8-b4b1-9a0334d76f84',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "76ebde5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"how many words are there in the sentence 'hello world, this is a test sentence?'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "41d26584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'I am sorry, I cannot fulfill this request. The available tools do not have the capability to count the number of words in a sentence.',\n",
       "  'extras': {'signature': 'CsIDAb4+9vvgNmPiWFpUrtNk7pWBVxzc50QOwm7tBp58HoHnMH9LHHZ6GYYAp8hcOp+4uBq5zc1wZL6hD6bjqtTf1IMp+5MF/4aOTLpFt2FH4YXUwqq4CagEHJxzzN/teTKegH6YOW9/cVoDIXtSjw33Y5YvhlV+JAYPwCQFQ5MnqTyNmJyvU+gpcLaZrg/2gDiRBWBDxT07qfsJzJH1lo++DJc/6EK3ZtBthA89NFiZGkfjHcjk62ShyIEaDD8BR4I1kdzhJgZQD+cRXlzio4FYtPEgCfCS2FYeyk3GzbT+Y2vdUzzIfx0wbHZiBC1Lqrnf1B67Y5K3jY2W3UAduVxJwhIOeMEMR5yadyqIPBPcH1B/mUPoixjZUdHZLXl9aR8Hdw4536LKRLTy2Y4AkoITyLlCVnrUFwnKQyhExoBCnbt3/QLmGXRSdkOpNdvLjGjuuKE40uvRmUuwHPcQzupdy081pL5gJ51BlZCYV711WvxR/3G8Ju2O7iVyHNVwSJIBs3CUbWLjJj128C8XasILLThUZTBsTbbTwC/ZOHc/9BIMqaphUoPlql+MYXA2WEsqnertMy7fd9TSoSOaKQpYrqG+'}}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "192a2f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'type': 'text', 'text': 'I am sorry, I cannot fulfill this request. The available tools do not have the capability to count the number of words in a sentence.', 'extras': {'signature': 'CsIDAb4+9vvgNmPiWFpUrtNk7pWBVxzc50QOwm7tBp58HoHnMH9LHHZ6GYYAp8hcOp+4uBq5zc1wZL6hD6bjqtTf1IMp+5MF/4aOTLpFt2FH4YXUwqq4CagEHJxzzN/teTKegH6YOW9/cVoDIXtSjw33Y5YvhlV+JAYPwCQFQ5MnqTyNmJyvU+gpcLaZrg/2gDiRBWBDxT07qfsJzJH1lo++DJc/6EK3ZtBthA89NFiZGkfjHcjk62ShyIEaDD8BR4I1kdzhJgZQD+cRXlzio4FYtPEgCfCS2FYeyk3GzbT+Y2vdUzzIfx0wbHZiBC1Lqrnf1B67Y5K3jY2W3UAduVxJwhIOeMEMR5yadyqIPBPcH1B/mUPoixjZUdHZLXl9aR8Hdw4536LKRLTy2Y4AkoITyLlCVnrUFwnKQyhExoBCnbt3/QLmGXRSdkOpNdvLjGjuuKE40uvRmUuwHPcQzupdy081pL5gJ51BlZCYV711WvxR/3G8Ju2O7iVyHNVwSJIBs3CUbWLjJj128C8XasILLThUZTBsTbbTwC/ZOHc/9BIMqaphUoPlql+MYXA2WEsqnertMy7fd9TSoSOaKQpYrqG+'}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c75a5-ed57-75c1-bc99-c9ceff70abe2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 157, 'output_tokens': 122, 'total_tokens': 279, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 94}})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7b1168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm should be call the particular tool call based on the user query and return the output of the tool call in the content of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9d2a6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"can you multiply 10 and 20?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a384a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358eb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 10, 'b': 20},\n",
       "  'id': '31cf88a7-4e96-4e11-9cd6-1b56d811830c',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls # call the appropriate tool based on the user query and return the output of the tool call in the cantent of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "94d8a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"hi how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "790bdfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm doing well, thank you! How can I help you today?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c75a9-2032-7063-aca5-e287e8248196-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 144, 'output_tokens': 16, 'total_tokens': 160, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572a116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you! How can I help you today?\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content # if the query is not related to any tool llm direlctly return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3df16859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1dcf916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"what was in the latest indian union budget report of 2026?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e32f2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'wikipedia', 'arguments': '{\"query\": \"Indian Union Budget report of 2026\"}'}, '__gemini_function_call_thought_signatures__': {'2a9eeb50-66ff-44da-9dac-50199f6dc9cf': 'CtwCAb4+9vudGpFRhWe17AFBblV2ASprl+EFfQV1ETDuwA7blKtZkD2TV5ot3atCcPyRraN04vv0NcQC1enimquVAMfUdwR5gH51hmGYa55+k3Qqu2rZXaOp4ARkd+msLm+5Is1jwZEioknmb0PpCJ5jfUU3DVuiu4GY9mfx8sDU0e+2AYYzb9qr28yW7OrUWzGc5eyTat+80TBGgD2yP29CNfy3qzT/3LnJQHQjAoy+jMbW9f9Qmg8b3H8cvvp0qWyMvo+4MoLCSUU2OiGNaJxCHa1HzSFKON0JuOUlVx+HE+yv0jY1CqzfvTKog0iipcralIDSJHspW7LI7WEHQmchKvk2r7/sDoLLvYflrM5xm7e3E7vak8jaDRxy4GvvZaFRtGg41lrqrDS8vOkz5KQf88DmUI0OWvx/1helk3QTNp5Ma26UXjbIyf93BCvq2HnuEJ+gdfi0kjziVjRS'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c75ad-2147-7102-bf3e-0974819475fe-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Indian Union Budget report of 2026'}, 'id': '2a9eeb50-66ff-44da-9dac-50199f6dc9cf', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 227, 'output_tokens': 95, 'total_tokens': 322, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 73}})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f2a77ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d640d4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': 'Indian Union Budget report of 2026'},\n",
       "  'id': '2a9eeb50-66ff-44da-9dac-50199f6dc9cf',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "022104d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState,StateGraph, END, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "663eb81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = SystemMessage(content=\"You are a helpful assistant that can use tools to answer questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "058e8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inbuilt messagestate from the langgraph package to handle the messages in the graph nodes and edges\n",
    "def function_1(state:MessagesState):\n",
    "    user_question=state[\"messages\"] # uestion will come from the user and it will be in the form of list of messages\n",
    "    input_question =[SYSTEM_PROMPT] + user_question # add the system prompt and user query\n",
    "    response = llm_with_tools.invoke(input_question) # pass the system prompt and user query to the llm with tools and get the response from the llm\n",
    "    return{\n",
    "        \"messages\":[response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "212d70d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='get_stock_price', description='this is a tool to get stock price using yfinance', args_schema=<class 'langchain_core.utils.pydantic.get_stock_price'>, func=<function get_stock_price at 0x00000189CEB33920>),\n",
       " StructuredTool(name='get_word_length', description='it is a tool to count the lenth of the word', args_schema=<class 'langchain_core.utils.pydantic.get_word_length'>, func=<function get_word_length at 0x00000189CEB331A0>),\n",
       " StructuredTool(name='multiply', description='Multiple the two integers function.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x00000189CECBEC00>),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\adnan\\\\Rajkumar\\\\ai_agents\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=5, lang='en', load_all_available_meta=False, doc_content_chars_max=500))]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b100572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_2 = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0ea16a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b671fa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x189e9aed730>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"llm\", function_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "adeabc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x189e9aed730>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"tools\", function_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "864c423d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x189e9aed730>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START, \"llm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "108ae4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x189e9aed730>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    tools_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b0a912a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x189e9aed730>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"tools\", \"llm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "83f77542",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "47f8f2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5c200302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tell me the stock price of Nvidia--> it will call the tool from the get_stock_price\n",
    "# ------> llm (routing) dot edge is nothing but the conditional edge which will decide which tool to call based on the user query and return the output of the tool call in the content of the result.\n",
    "# we are giving a capapbility to the llm, how we giving the capability to the llm, --->we are giving the capability to the llm by adding the tool node in the graph and connecting the llm node to the tool node with the conditional edge which will decide which tool to call based on the user query and return the output of the tool call in the content of the result.\n",
    "# binidg the tool and system propmt tools\n",
    "# routing perform the conditional routing based on the user query and call the appropriate tool and return the output of the tool call in the content of the result.\n",
    "# we can use the mcp. This is the basic agent workflow or orchastration workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2fa916",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"what is the stock price of TCS.NS?\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf516a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the stock price of TCS.NS?', additional_kwargs={}, response_metadata={}, id='b2dbc1eb-7e2c-4c43-9fda-09accdebf980'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_stock_price', 'arguments': '{\"ticker\": \"TCS.NS\"}'}, '__gemini_function_call_thought_signatures__': {'4dfddfc2-a2a2-470b-939d-1f0ecce7053d': 'CtABAb4+9vsBFKSpRwlt/gg4X8J64NPr8Ag78q6Kj31FVcRdpu0bT1m7KymyR4IdxGAN3QOTYw2heQ4aiJPS9yGGCWTYsezYW5rOYni+kwa66tR3FBMNhpwz+hndUtYuz5zyEeRy6EUi0724dyl8M6gTNZ/J3fqIf79VLGjcX6zK2R4g4zVepl7h8lasnGi/NRSW4/lqFm1yNycJdHge/Kpfq+q7pCN6Txlb5/LfbYQy5HtcT8GAg4kjM+2zcl7XPRa24y57peNHl0B+BtyuXycI+Q=='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c75c1-b6c6-7751-86ab-1972acb93340-0', tool_calls=[{'name': 'get_stock_price', 'args': {'ticker': 'TCS.NS'}, 'id': '4dfddfc2-a2a2-470b-939d-1f0ecce7053d', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 234, 'output_tokens': 69, 'total_tokens': 303, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 49}}),\n",
       "  ToolMessage(content='The last closing price of TCS.NS was 2677.90.', name='get_stock_price', id='b3d8be34-cf73-4fe2-a1fc-b5cf1e16ec0c', tool_call_id='4dfddfc2-a2a2-470b-939d-1f0ecce7053d'),\n",
       "  AIMessage(content='The last closing price of TCS.NS was 2677.90.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c75c1-c0a4-7321-bc96-6125f543f212-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 288, 'output_tokens': 18, 'total_tokens': 306, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495670f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the stock price of TCS.NS?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_stock_price (4dfddfc2-a2a2-470b-939d-1f0ecce7053d)\n",
      " Call ID: 4dfddfc2-a2a2-470b-939d-1f0ecce7053d\n",
      "  Args:\n",
      "    ticker: TCS.NS\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_stock_price\n",
      "\n",
      "The last closing price of TCS.NS was 2677.90.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The last closing price of TCS.NS was 2677.90.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"how to track the result\"\"\"\n",
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f74e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"what was in the latest indian union budget report of 2026?\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e34202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what was in the latest indian union budget report of 2026?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (07a88b48-9a1c-447a-9d69-8db67fa0a8b4)\n",
      " Call ID: 07a88b48-9a1c-447a-9d69-8db67fa0a8b4\n",
      "  Args:\n",
      "    query: Indian union budget report of 2026\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: 2025 Union budget of India\n",
      "Summary: The  2025 Union budget of India was presented by Finance Minister Nirmala Sitharaman on 1 February 2025 for the financial year 2025-2026. This was the first full financial year budget of Prime Minister Narendra Modi's third term in office.\n",
      "\n",
      "Page: Military budget of India\n",
      "Summary: The military budget or defence budget of India is the portion of the overall budget of Union budget of India that is allocated for the funding of the Indian Armed Forces. The mi\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"The 2025 Union budget of India was presented on 1 February 2025 for the financial year 2025-2026. This was the first full financial year budget of Prime Minister Narendra Modi's third term in office. I don't have information about a separate 2026 budget report.\", 'extras': {'signature': 'Cr8GAb4+9vsiDGkvfquyh2JwNSXQb52ayIzjcDuzjnqxSvjOPSiYmH/eICdxgAyx8AJlGX2OxEiFOUTqZmy/t1UaeSKRiNcMr7dspoXtX+smtVj++pZ9WyYrwCw3JzkwyZ+C998c/6DWfYU5tsPR+IglBl74N9/KPP5//nK48siabk3kwebeG2ieSI6UXRitQaioRx2jMHM0jMwxMzsqUDXIXyBL7DYVTaxdxQ+9igl+h7CfLiOzsJRFu3NAX4RKiNw7x7CvEmkfAIsJde1ElmABNz7WdF6R9PgbBDH5r1a8dR6J7N6eP1fP0vGKf+kWxfh4wGrL0oeyPpD+x7bDxbPVwKYxpTAqR6Yg2ujfw2eq0yjMC9yu3PzEsH8Q1L0QqLWwtssfnvtuIyPL9dGUcuHUYvTuA6wqoLukzG9jXKOxJwRiYCRZ8YxHt75HPYe9pUDKa3vhssXKXhVfY/SI1xCLFBqpuMt7QBe39HF6qb/TQenAxRyK9+ibam0Kw9aqORbc64q62uCpd8siZHBtu+yV0sTFlz8+GN7aZ8hTCtIIpiwznvj0a8w9+79GegGLtSj7LDgICZhbTfGT/pdjm1rExFbdMoZN3DQsw6yI8JKyTJvIdfWDeeOcPsODU9C8ILxM+9Ns2yz973zO7fO72t3ZigSWiXdse+YDF2YOsxm1Kvxw6z8QZr8SJtN2c79oN8hzvj/EKhFlHfpcRS1848SbGUjz6/yJFAM1uU3N9YsHz4QzDyOKtiL/Plowccsctx9ASDiyGyPXLaNmyFD/y17aNcNSckEyohZWHZJ/0msM9BSnnwNJsJtzkt3n7HCFK7oRZVIjd3mDzv/V/mYmFTg629jpr0BoS1+Dcx+ON2x31Pf5XxEuZdGSDIlFMEm5LDSIBZf50RWOfrHckV7FrVv3eiB5Tkc8Vs9W9bZSihHc+tNueRaod6JcW5in8fn1cuP/2fWuxQ40VjhE4+ykVS+djqhZE0MURNATSp8FciY1Dz5096ab37XnLEJev3A478jGgTaIK2IPUYjx8bQO2hKHwu6RV3ptSv3UGaYb8gzOQ5gWykUDCqqC1TndJk1UhUbEoFWOZPxO683FWj6cOKcN'}}]\n"
     ]
    }
   ],
   "source": [
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"give me the latest AI news count the length of response and multiply that response with the 10.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb530e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "give me the latest AI news count the length of response and multiply that response with the 10.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'I am sorry, I cannot give you the latest AI news. The available tools do not have the capability to fetch real-time news.', 'extras': {'signature': 'CoUFAb4+9vs3s5ykt2UV/bpaNW3deA1JwW6XWYv+BGwzXjpt/tPBO4wsBm6MPbku36uGaHAZAuLZ8e4NoLlyAJHHaTf1OeNTK+hfIiG5jAkKpRAZxYFpQQzkeWvkbNkM8A3NGFxh63277or0MvGA+JXpVsoleGPfdNxx6IuptJEH2vKDBF58/yjqJMuxY/RdXPdVagblahEELXLtnGepzpy3UVzSwNqJftEgPnARN1Q8tkxtfIfUv9aya6plt32sgcbNk4rIweqfwYlIr9oIs8ZmvKqMVhcJVNJWFJRuUoV4Tk4igiZ2/u2o1GxPT8dDpbIZHJp8plBgjjiMrKHWALAjO0EqHZw5bl4EBUHylH8k0e0DuyOR+1WCLtLiJhJ/v6lg7ik9FOcd0vFmcJc7koMxuZFsw2w0q/lKhdzNorbH+u3swfS4hcdtLm7NdBhFFN1wrXY4ZFn1vBTCpj9eC86oYpKydBWYc8XpV9WRNlpMEL/MWbTaaPPslgrQVDy7dtsTj4KyKRF9RkhFOV/5zdXf7+ZEahFZJLGOaHAPEg1DDI3c88tQV+I0QfAh4BE3nW+hXoYSNjFSDVhsOuO6Hu99y8ReWERoIyYFuRbta3B+9I3Z4ZfU6hWeDv5Ki5VyJvyohWFFbtJmQQQvRO5aBke2i0aPEYjeqtFMoEKNHyrWhfAq9sbzFULA+N20a0fAmUQqIJDZrpKJxNYWyzTggR/noH5EmTDrg4Gt6UjqoKRV1DG125xgMdB0Xy+gd8HVfRy9jFmpTlCQtd0m9qD3VGcPUFfE2eg82TaSG7TcfSJ2Ew+iRiPOOqmaBugBF3ylt4f1B4XzXrzRbYDuenvo0SkBQ7o7XJ6p'}}]\n"
     ]
    }
   ],
   "source": [
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048528af",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"how did trump's tariff policy impact the TCS.NS?\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4314f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "how did trump's tariff policy impact the TCS.NS?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (e6bfbf3b-1ba8-46c2-ba57-01a49f8bfa1a)\n",
      " Call ID: e6bfbf3b-1ba8-46c2-ba57-01a49f8bfa1a\n",
      "  Args:\n",
      "    query: Trump's tariff policy\n",
      "  wikipedia (2feb3522-1595-48af-a079-ea618c6b0d2b)\n",
      " Call ID: 2feb3522-1595-48af-a079-ea618c6b0d2b\n",
      "  Args:\n",
      "    query: TCS.NS\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: Tariffs in the second Trump administration\n",
      "Summary: During his second term as President of the United States, Donald Trump enacted a series of steep tariffs affecting nearly all goods imported into the country. From January to April 2025, the overall average effective US tariff rate rose from 2.5% to an estimated 27%the highest level in over a century. After changes and negotiations, the overall average effective tariff rate was 16.8% as of November 2025. US tariff revenue was $287 billio\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: TCS-1205\n",
      "Summary: TCS 1205 is a GABAA receptor positive allosteric modulator of the tryptamine family. It is a benzodiazepine site agonist selective for certain subunits.\n",
      "\n",
      "Page: T-Bank\n",
      "Summary: T-Bank (Russian: -), formerly known as Tinkoff Bank is a Russian commercial bank based in Moscow and founded by Oleg Tinkov in 2006. Up until 2024, the bank did not have branches and was considered a neobank. It is the second largest provider of credit cards in Russia, and is one of the world's\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (3e672a64-2081-4244-8e7c-5267c703a6ad)\n",
      " Call ID: 3e672a64-2081-4244-8e7c-5267c703a6ad\n",
      "  Args:\n",
      "    query: Tata Consultancy Services\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: Tata Consultancy Services\n",
      "Summary: Tata Consultancy Services Limited (TCS) is an Indian multinational technology company specializing in information technology services and consulting. Headquartered in Mumbai, it is a part of the Tata Group and operates in 150 locations across 46 countries. As of 2024, Tata Sons owned 71.74% of TCS, and close to 80% of Tata Sons' dividend income came from TCS.\n",
      "TCS ranked seventh on the Fortune India 500 list for 2024. In September 2021, TCS recorded a mark\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"Trump's tariff policy primarily focused on imposing tariffs on imported goods into the United States. Tata Consultancy Services (TCS.NS) is an Indian multinational technology company specializing in information technology services and consulting.\\n\\nSince TCS primarily provides services rather than exporting physical goods, a direct impact from tariffs on goods is unlikely. However, there could have been indirect impacts:\\n\\n*   **Impact on clients:** If Trump's tariffs negatively affected TCS's clients (e.g., US companies whose businesses were impacted by tariffs), those clients might have reduced their IT spending, which could indirectly affect TCS's revenue.\\n*   **Economic uncertainty:** The broader economic uncertainty and potential trade wars resulting from the tariff policies could have led to a general slowdown in global IT spending, potentially impacting TCS.\\n\\nWithout more specific information on any tariffs or trade policies directly targeting IT services or outsourcing from India during Trump's administration, it's difficult to quantify a precise impact on TCS.NS.\", 'extras': {'signature': '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'}}]\n"
     ]
    }
   ],
   "source": [
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaefb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proper planning and proper execution is achieved by the deepagents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0cd1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e92bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e8877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0774c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
